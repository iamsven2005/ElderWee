
<style>

  @use "@material";
  body {
    font-family: roboto;
    margin: 2em;
    color: #3d3d3d;
    --mdc-theme-primary: #007f8b;
    --mdc-theme-on-primary: #f1f3f4;
  }
  
  h1 {
    color: #007f8b;
  }
  
  h2 {
    clear: both;
  }
  
  em {
    font-weight: bold;
  }
  
  video {
    clear: both;
    display: block;
    transform: rotateY(180deg);
    -webkit-transform: rotateY(180deg);
    -moz-transform: rotateY(180deg);
  }
  
  section {
    opacity: 1;
    transition: opacity 500ms ease-in-out;
  }
  
  .mdc-button.mdc-button--raised.removed {
    display: none;
  }
  
  .invisible {
    opacity: 0.2;
  }
  
  .videoView,
  .detectOnClick {
    position: relative;
    float: left;
    width: 48%;
    margin: 2% 1%;
    cursor: pointer;
  }
  
  .detectOnClick p {
    position: absolute;
    padding: 5px;
    background-color: #007f8b;
    color: #fff;
    border: 1px dashed rgba(255, 255, 255, 0.7);
    z-index: 2;
    font-size: 12px;
    margin: 0;
  }
  
  .videoView p {
    position: absolute;
    padding-bottom: 5px;
    padding-top: 5px;
    background-color: #007f8b;
    color: #fff;
    border: 1px dashed rgba(255, 255, 255, 0.7);
    z-index: 2;
    font-size: 12px;
    margin: 0;
  }
  
  .highlighter {
    background: rgba(0, 255, 0, 0.25);
    border: 1px dashed #fff;
    z-index: 1;
    position: absolute;
  }
  
  .detectOnClick {
    z-index: 0;
  }
  
  .detectOnClick img {
    width: 100%;
  }
  .key-point {
    position: absolute;
    z-index: 1;
    width: 3px;
    height: 3px;
    background-color: #ff0000;
    /* border: 1px solid #ffffff; */
    border-radius: 50%;
    display: block;
  }
  </style>

  <link href="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.css" rel="stylesheet">
  <script src="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.js"></script>
  
    <div id="liveView" class="videoView">
      <button id="webcamButton" class="mdc-button mdc-button--raised">
        <span class="mdc-button__ripple"></span>
        <span class="mdc-button__label">ENABLE WEBCAM</span>
      </button>
      <video id="webcam" autoplay="" playsinline=""></video>
    </div>
        <script id="rendered-js" type="module">

  import { FaceDetector, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";
  const demosSection = document.getElementById("demos");
  let faceDetector;
  let runningMode = "IMAGE";
  // Initialize the object detector
  const initializefaceDetector = async () => {
      const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm");
      faceDetector = await FaceDetector.createFromOptions(vision, {
          baseOptions: {
              modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite`,
              delegate: "GPU"
          },
          runningMode: runningMode
      });
      demosSection.classList.remove("invisible");
  };
  initializefaceDetector();

  const imageContainers = document.getElementsByClassName("detectOnClick");
  for (let imageContainer of imageContainers) {
      imageContainer.children[0].addEventListener("click", handleClick);
  }

  async function handleClick(event) {
      const highlighters = event.target.parentNode.getElementsByClassName("highlighter");
      while (highlighters[0]) {
          highlighters[0].parentNode.removeChild(highlighters[0]);
      }
      const infos = event.target.parentNode.getElementsByClassName("info");
      while (infos[0]) {
          infos[0].parentNode.removeChild(infos[0]);
      }
      const keyPoints = event.target.parentNode.getElementsByClassName("key-point");
      while (keyPoints[0]) {
          keyPoints[0].parentNode.removeChild(keyPoints[0]);
      }
      if (!faceDetector) {
          console.log("Wait for objectDetector to load before clicking");
          return;
      }
      // if video mode is initialized, set runningMode to image
      if (runningMode === "VIDEO") {
          runningMode = "IMAGE";
          await faceDetector.setOptions({ runningMode: "IMAGE" });
      }
      const ratio = event.target.height / event.target.naturalHeight;
      // faceDetector.detect returns a promise which, when resolved, is an array of Detection faces
      const detections = faceDetector.detect(event.target).detections;
      console.log(detections);
      displayImageDetections(detections, event.target);
  }
  function displayImageDetections(detections, resultElement) {
      const ratio = resultElement.height / resultElement.naturalHeight;
      console.log(ratio);
      for (let detection of detections) {
          // Description text
          const p = document.createElement("p");
          p.setAttribute("class", "info");
          p.innerText =
              "Confidence: " +
                  Math.round(parseFloat(detection.categories[0].score) * 100) +
                  "% .";
          // Positioned at the top left of the bounding box.
          // Height is whatever the text takes up.
          // Width subtracts text padding in CSS so fits perfectly.
          p.style =
              "left: " +
                  detection.boundingBox.originX * ratio +
                  "px;" +
                  "top: " +
                  (detection.boundingBox.originY * ratio - 30) +
                  "px; " +
                  "width: " +
                  (detection.boundingBox.width * ratio - 10) +
                  "px;" +
                  "hight: " +
                  20 +
                  "px;";
          const highlighter = document.createElement("div");
          highlighter.setAttribute("class", "highlighter");
          highlighter.style =
              "left: " +
                  detection.boundingBox.originX * ratio +
                  "px;" +
                  "top: " +
                  detection.boundingBox.originY * ratio +
                  "px;" +
                  "width: " +
                  detection.boundingBox.width * ratio +
                  "px;" +
                  "height: " +
                  detection.boundingBox.height * ratio +
                  "px;";
          resultElement.parentNode.appendChild(highlighter);
          resultElement.parentNode.appendChild(p);
          for (let keypoint of detection.keypoints) {
              const keypointEl = document.createElement("spam");
              keypointEl.className = "key-point";
              keypointEl.style.top = `${keypoint.y * resultElement.height - 3}px`;
              keypointEl.style.left = `${keypoint.x * resultElement.width - 3}px`;
              resultElement.parentNode.appendChild(keypointEl);
          }
      }
  }

  let video = document.getElementById("webcam");
  const liveView = document.getElementById("liveView");
  let enableWebcamButton;
  // Check if webcam access is supported.
  const hasGetUserMedia = () => { var _a; return !!((_a = navigator.mediaDevices) === null || _a === void 0 ? void 0 : _a.getUserMedia); };
  // Keep a reference of all the child elements we create
  // so we can remove them easilly on each render.
  var children = [];
  // If webcam supported, add event listener to button for when user
  // wants to activate it.
  if (hasGetUserMedia()) {
      enableWebcamButton = document.getElementById("webcamButton");
      enableWebcamButton.addEventListener("click", enableCam);
  }
  else {
      console.warn("getUserMedia() is not supported by your browser");
  }
  // Enable the live webcam view and start detection.
  async function enableCam(event) {
      if (!faceDetector) {
          alert("Face Detector is still loading. Please try again..");
          return;
      }
      // Hide the button.
      enableWebcamButton.classList.add("removed");
      // getUsermedia parameters
      const constraints = {
          video: true
      };
      // Activate the webcam stream.
      navigator.mediaDevices
          .getUserMedia(constraints)
          .then(function (stream) {
          video.srcObject = stream;
          video.addEventListener("loadeddata", predictWebcam);
      })
          .catch((err) => {
          console.error(err);
      });
  }
  let lastVideoTime = -1;
  async function predictWebcam() {
      // if image mode is initialized, create a new classifier with video runningMode
      if (runningMode === "IMAGE") {
          runningMode = "VIDEO";
          await faceDetector.setOptions({ runningMode: "VIDEO" });
      }
      let startTimeMs = performance.now();
      // Detect faces using detectForVideo
      if (video.currentTime !== lastVideoTime) {
          lastVideoTime = video.currentTime;
          const detections = faceDetector.detectForVideo(video, startTimeMs)
              .detections;
          displayVideoDetections(detections);
      }
      // Call this function again to keep predicting when the browser is ready
      window.requestAnimationFrame(predictWebcam);
  }
  function displayVideoDetections(detections) {
      // Remove any highlighting from previous frame.
      for (let child of children) {
          liveView.removeChild(child);
      }
      children.splice(0);
      // Iterate through predictions and draw them to the live view
      for (let detection of detections) {
          const p = document.createElement("p");
          p.innerText =
              "Confidence: " +
                  Math.round(parseFloat(detection.categories[0].score) * 100) +
                  "% .";
          p.style =
              "left: " +
                  (video.offsetWidth -
                      detection.boundingBox.width -
                      detection.boundingBox.originX) +
                  "px;" +
                  "top: " +
                  (detection.boundingBox.originY - 30) +
                  "px; " +
                  "width: " +
                  (detection.boundingBox.width - 10) +
                  "px;";
          const highlighter = document.createElement("div");
          highlighter.setAttribute("class", "highlighter");
          highlighter.style =
              "left: " +
                  (video.offsetWidth -
                      detection.boundingBox.width -
                      detection.boundingBox.originX) +
                  "px;" +
                  "top: " +
                  detection.boundingBox.originY +
                  "px;" +
                  "width: " +
                  (detection.boundingBox.width - 10) +
                  "px;" +
                  "height: " +
                  detection.boundingBox.height +
                  "px;";
          liveView.appendChild(highlighter);
          liveView.appendChild(p);
          // Store drawn objects in memory so they are queued to delete at next call
          children.push(highlighter);
          children.push(p);
          for (let keypoint of detection.keypoints) {
              const keypointEl = document.createElement("spam");
              keypointEl.className = "key-point";
              keypointEl.style.top = `${keypoint.y * video.offsetHeight - 3}px`;
              keypointEl.style.left = `${video.offsetWidth - keypoint.x * video.offsetWidth - 3}px`;
              liveView.appendChild(keypointEl);
              children.push(keypointEl);
          }
      }
  }
      </script>

  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm/vision_wasm_internal.js" crossorigin="anonymous"></script>